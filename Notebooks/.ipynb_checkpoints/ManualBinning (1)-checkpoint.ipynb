{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f82c33",
   "metadata": {
    "id": "32f82c33"
   },
   "source": [
    "## Fitting Sigmoid to empirical NN\n",
    "### Manually selecting bin size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "578550d4",
   "metadata": {
    "id": "578550d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9 Species: AT, CE, DM, ...\n",
    "# 8 Classes: ER, ERDD, GEO, GEOGD ...(each with ~500 data points)\n",
    "# normalization is done on each species seperetaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "661f35d5",
   "metadata": {
    "id": "661f35d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f33722",
   "metadata": {
    "id": "78f33722"
   },
   "source": [
    "### normalization on AT,CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ac805cf",
   "metadata": {
    "id": "9ac805cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = ['ER', 'ERDD', 'GEO', 'GEOGD', 'HGG', 'SF', 'SFDD', 'Sticky', 'Original']\n",
    "classes_pred = ['ER', 'ERDD', 'GEO', 'GEOGD', 'HGG', 'SF', 'SFDD', 'Sticky']\n",
    "#data_locations = [r\"/content/drive/MyDrive/random stuff/Adaptable-Sigmoids/data/AT\"+c for c in classes]\n",
    "# data_locations = [r\"/Users/lizongli/Desktop/knnResearch/Adaptable-Sigmoids/data/EC\"+c for c in classes]\n",
    "data_locations = [r\"../data/EC\"+c for c in classes]\n",
    "#data_locations_CE = [r\"/content/drive/MyDrive/random stuff/Adaptable-Sigmoids/data/CE\"+c for c in classes]\n",
    "data_locations_CE = [r\"../data/CE\"+c for c in classes]\n",
    "#prediction_p_value = \"/content/drive/MyDrive/random stuff/Adaptable-Sigmoids/data/ATOriginal\"\n",
    "prediction_p_value = \"../data/ECOriginal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "yDG_jpCJzcLt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDG_jpCJzcLt",
    "outputId": "473393f9-7a1e-43e0-a95f-5ae1897f5c90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec21fafc",
   "metadata": {
    "id": "ec21fafc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_data(data_location,classes):\n",
    "    df_comb = pd.DataFrame()\n",
    "    i = 0\n",
    "    for protein in data_location:\n",
    "        df = pd.read_csv(protein, header = None, sep = ' ')\n",
    "        df['class'] = classes[i]\n",
    "        df_comb = pd.concat([df, df_comb])\n",
    "        i += 1\n",
    "    return df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b59b92a",
   "metadata": {
    "id": "4b59b92a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comb = combine_data(data_locations,classes)\n",
    "df_class = df_comb['class']\n",
    "df_comb = df_comb.drop(\"class\", axis = 1)\n",
    "df_comb = pd.DataFrame(MinMaxScaler().fit_transform(df_comb))\n",
    "df_comb['class'] = df_class.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36b4276a",
   "metadata": {
    "id": "36b4276a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_CE = combine_data(data_locations_CE,classes)\n",
    "# df_class_CE = df_CE['class']\n",
    "# df_CE = df_CE.drop(\"class\", axis = 1)\n",
    "# df_CE = pd.DataFrame(MinMaxScaler().fit_transform(df_CE))\n",
    "# df_CE['class'] = df_class_CE.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca699776",
   "metadata": {
    "id": "ca699776",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calling data(data_frame, class_name) return Species-Class empirical data as an array\n",
    "def data(dataframe, class_name):\n",
    "    return dataframe[dataframe['class']==class_name].drop(\"class\",axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d691bd",
   "metadata": {
    "id": "c3d691bd"
   },
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24614231",
   "metadata": {
    "id": "24614231",
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1879277309.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[59], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(np.array(shortest_distance)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# calculating empirical data's shortest(NN) distance \n",
    "# real data is high-dimensional data points\n",
    "def data_distance(data):\n",
    "    shortest_distance = [0]*len(data)\n",
    "    for i in range(len(data)):\n",
    "        x = np.delete(data,i,0)\n",
    "        temp = (x-data[i])**2\n",
    "        d = np.sqrt(np.sum(temp,axis=1))\n",
    "        shortest_distance[i] = d.min()\n",
    "    print(np.array(shortest_distance))\n",
    "    return np.array(shortest_distance)   # return an array of real data's NN distance\n",
    "\n",
    "\n",
    "# plotting empirical data's NN hist\n",
    "def plot_data_distance(D, title):\n",
    "    \"\"\"\n",
    "    D: an array of real data' NN distance\n",
    "    \"\"\"\n",
    "    f, ax = plt.subplots(1,1, figsize = (6,4))\n",
    "    ax.hist(D,edgecolor='white',bins=100)   ## consider specifying <bins>\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "# generate empirical CDF manually, satisfying:\n",
    "# 1. F(x<=0) = 0\n",
    "# 2. F(x_1) = 1/(n+1)\n",
    "# 3. F(x_n/2) = 0.5\n",
    "# 4. F(x_n) = n/(n+1)\n",
    "# 5. F(x) < 1 for all x.\n",
    "def empirical_CDF(data,title):\n",
    "    '''\n",
    "    return x,y data of CDF \n",
    "    '''    \n",
    "    sort_data = np.sort(data)\n",
    "    #print(\"data len: \",len(sort_data))\n",
    "    x = np.concatenate(([0],sort_data))\n",
    "    #print(\"x len : \",len(x))\n",
    "    #print(\"first: \", x[0], \"\\nlast: \",x[-1])\n",
    "    \n",
    "    y = np.zeros((x.shape))\n",
    "    for i in range(1,len(x)):\n",
    "        y[i] = i/len(x)\n",
    "    # plot_data_distance(x, \"a\")\n",
    "    # print(plt.show())\n",
    "    # print(x)\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n",
    "# curve_fit()\n",
    "def auto_curve_fit(data_NN, x, y, x_scale_factor, func, s, p_control=None):\n",
    "    '''\n",
    "    data_NN: array empirical data_distance for calculating median\n",
    "    x,y: from CDF\n",
    "    s: sigma in curve_fit(), for weighting\n",
    "    '''\n",
    "    if p_control == \"Gompertz\":\n",
    "        p0 = [1,1]\n",
    "    elif p_control == \"Weight\":\n",
    "        p0 = [np.median(data_NN)/x_scale_factor,1,0.5]\n",
    "    else:\n",
    "        p0 = [np.median(data_NN)/x_scale_factor,1] # this is initial guess for sigmoid parameters\n",
    "    \n",
    "    popt, pcov = curve_fit(f=func, xdata=x/x_scale_factor, ydata=y, p0=p0,method='lm')\n",
    "\n",
    "    # parameters yielded by Curve_fit: x0, k\n",
    "    print(\"curve_fit parameter on \"+str(func)[9:-22]+\": \", popt)\n",
    "    return popt\n",
    "\n",
    "arctan_popt = {}\n",
    "\n",
    "# def sigmoid_entropy(x, y, f):\n",
    "#     return np.sum(y*np.log(f(x)) + (1-y)*np.log(1 - f(x)))\n",
    "\n",
    "# plot fitted sigmoid and empirical curve in 1-y and y: i.e. y-axis = p-value and CDF\n",
    "def sigmoids_for_class(data, name, factor, func_list, color_list, binning=False):\n",
    "    if binning:\n",
    "        x,y = binning_xy(data_binning(data))\n",
    "    else:\n",
    "        x,y = empirical_CDF(data, name)\n",
    "    # plt.plot(x/factor, y)\n",
    "    # plt.show()\n",
    "    # print(y.shape)\n",
    "    # axis[0] = 1-y = p_value (on log space)\n",
    "    # axis[1] = y = CDF\n",
    "    f,ax = plt.subplots(1,2,figsize=(16,6))\n",
    "    ax[0].set_title('1-y(p_value) of '+name)\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].scatter(x,1-y, color='b',s=10)\n",
    "    # ax[0].plot(x, 1-y, color=\"b\")\n",
    "    \n",
    "    ax[1].set_title('y of '+name)\n",
    "    ax[1].scatter(x,y, color='b',s=10)\n",
    "    # ax[1].plot(x, y, color=\"b\")\n",
    "    \n",
    "    print(\"For \",name,\" :\")\n",
    "    for i in range(len(func_list)):\n",
    "        try:\n",
    "            if i == 7:\n",
    "                p = auto_curve_fit(data,x,y,factor,func_list[i],s=y,p_control=\"Gompertz\")\n",
    "            elif i == 6:\n",
    "                p = auto_curve_fit(data,x,y,factor,func_list[i],s=y,p_control=\"Weight\")\n",
    "            else:\n",
    "                p = auto_curve_fit(data,x,y,factor,func_list[i],s=y)\n",
    "        except RuntimeError:\n",
    "            print(\"error in \",str(func_list[i])[9:-22])\n",
    "            continue\n",
    "        # y = y/factor\n",
    "        y2 = func_list[i](x/factor, *p)\n",
    "        # print(len(x/factor))\n",
    "        # print(y2)\n",
    "        if func_list[i] == arctan:\n",
    "          arctan_popt[f\"{name}\"] = p\n",
    "\n",
    "        if func_list[i] == arctan_GD:\n",
    "            # y2 = func_list[i](x/factor, *p)\n",
    "            # print(y2)\n",
    "            # print(y)\n",
    "            # error = sigmoid_entropy(x/factor, y, func_list[i])\n",
    "            # plt.plot(x, y)\n",
    "            # plt.plot(x/factor, (y2-y)**2)\n",
    "            # plt.show()\n",
    "\n",
    "            # print(((y2-y)**2)[-20:])\n",
    "            # error = np.sum((y2[-20:] - y[-20:])**2)\n",
    "            # print(str(error))\n",
    "            # print(\"-----------\")\n",
    "            # error = np.sum(((1-y2) - (1-y))**2)\n",
    "            error = np.log(np.sum(np.exp(2 * ((1-y2) - (1-y)))))\n",
    "            print(\"arctan_GD: \" + str(error))\n",
    "            ax[0].plot(x, 1-y2, color=color_list[i], label=str(func_list[i])[9:-22])\n",
    "            ax[1].plot(x, y2, color=color_list[i], label=str(func_list[i])[9:-22])\n",
    "\n",
    "        if func_list[i] == arctan:\n",
    "            # y2 = func_list[i](x/factor, *p)\n",
    "            # print(y2)\n",
    "            # print(((y2-y)**2)[-20:])\n",
    "            # error = np.sum((y2[-20:] - y[-20:])**2)\n",
    "            # print(str(error))\n",
    "            # print(\"-----------\")\n",
    "            # error = np.sum(((1-y2) - (1-y))**2)\n",
    "            error = np.log(np.sum(np.exp(2 * ((1-y2) - (1-y)))))\n",
    "            # error = sigmoid_entropy(x/factor, y, func_list[i])\n",
    "            # plt.plot(x, y)\n",
    "            # plt.plot(x/factor, (y2-y)**2)\n",
    "            # plt.show()\n",
    "            print(\"Gom: \" + str(error))\n",
    "            ax[0].plot(x, 1-y2, color=color_list[i], label=str(func_list[i])[9:-22])\n",
    "            ax[1].plot(x, y2, color=color_list[i], label=str(func_list[i])[9:-22])\n",
    "        y2-y\n",
    "        (1-y2)-(1-y)\n",
    "        1-y2-1+y \n",
    "    ax[0].legend(loc='lower left')\n",
    "    ax[1].legend(loc='lower left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092f754",
   "metadata": {
    "id": "f092f754"
   },
   "source": [
    "### Sigmoid functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ceb679",
   "metadata": {
    "id": "f7ceb679",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.11 Adjust range to (0,1)\n",
    "\n",
    "def logistic(x,x0, k):\n",
    "    m = (1/ (1 + np.exp(-k*(x-x0))))      \n",
    "    return m\n",
    "\n",
    "def tanh(x, x0, k): \n",
    "    m = (1+np.tanh(k*(x-x0)))/2\n",
    "    return m\n",
    "\n",
    "def arctan(x, x0, k):\n",
    "    m = (1+(2/np.pi)*np.arctan(k*(x-x0)))/2\n",
    "    return m\n",
    "\n",
    "def GD(x, x0, k):\n",
    "    m = (1+(4/np.pi)*np.arctan(np.tanh(k*(x-x0))))/2\n",
    "    return m\n",
    "\n",
    "def ERF(x, x0, k):\n",
    "    m = (1+erf(k*(x-x0)))/2\n",
    "    return m\n",
    "\n",
    "def algebra(x, x0, k):\n",
    "    m = (1+x/((1+abs(x)**k)**(1/k)))/2\n",
    "    return m\n",
    "\n",
    "def arctan_GD(x,x0,k, w):\n",
    "    # print(x)\n",
    "    # print(x0)\n",
    "    # print(k)\n",
    "    # print(w)\n",
    "    m = w*GD(x,x0,k)+(1-w)*arctan(x,x0,k)\n",
    "    return m\n",
    "\n",
    "def Gompertz(x,b,c):\n",
    "    m = np.e**(-np.e**(b-c*x))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759ea63",
   "metadata": {
    "id": "1759ea63"
   },
   "source": [
    "### Fitting on All points without binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a6742",
   "metadata": {
    "id": "7b9a6742",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "factors = [1e-5,  1e-2,   1e-4,   1e-3,   1e-2,  1e-4, 1e-2,   1e-3]\n",
    "# factors = [1,1,1,1,1,1,1,1]\n",
    "colors = ['g','r','c','m','y','k','brown','gray']\n",
    "functions = [logistic, tanh, arctan, GD, ERF, algebra, arctan_GD, Gompertz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd3739",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d8bd3739",
    "outputId": "7dd8b15a-e88b-4e11-a917-29d77bfc5b02",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AT\n",
    "for i in range(len(classes_pred[:-1])):\n",
    "    data_i = data_distance(data(df_comb,classes_pred[:-1][i]))\n",
    "    sigmoids_for_class(data_i, classes_pred[:-1][i], np.mean(data_i), functions, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9f38a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bfc9f38a",
    "outputId": "22b7442f-6b22-438f-ee20-de1baf495c7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(classes[:-1])):\n",
    "    data_i = data_distance(data(df_CE,classes[:-1][i]))\n",
    "    sigmoids_for_class(data_i, classes[:-1][i], np.mean(data_i), functions, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3b44d",
   "metadata": {
    "id": "f5f3b44d"
   },
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979862b2",
   "metadata": {
    "id": "979862b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# binning first, add (0,0) at the front later when calculate y\n",
    "#make it smooth\n",
    "\n",
    "def data_binning(data):\n",
    "    \n",
    "    x = np.sort(data) \n",
    "    N = len(x)                   # e.g N = 500, sqrt(500)=22.3\n",
    "    lower = int(np.floor(np.sqrt(N))) # 22\n",
    "    upper = int(np.ceil(np.sqrt(N)))  # 23 as total #of bin\n",
    "    \n",
    "    if lower*upper >= N:\n",
    "        small_bin_num = int(lower*upper - N)  # 22*23 - 500 = 6\n",
    "        small_bin_size = int(lower - 1)  # 21\n",
    "        large_bin_size = lower\n",
    "    else: # HGG -> sqrt(252) = 15.8\n",
    "        small_bin_num = int(upper**2 - N) # 16*16-252 =4\n",
    "        small_bin_size = lower  # 15\n",
    "        large_bin_size = upper\n",
    "    \n",
    "    large_bin_num = int(upper - small_bin_num) # 23-6 = 17\n",
    "\n",
    "    # small_bin_size*small_bin_num + lower*large_bin_num = N\n",
    "\n",
    "    bin_count = [large_bin_size]*large_bin_num + [small_bin_size]*small_bin_num  # [22..*17, 21..*6,]\n",
    "    print(\"items in each bin: \", bin_count)\n",
    "    binned_data = []\n",
    "    i = 0\n",
    "    for count in bin_count:\n",
    "        binned_data.append(np.mean(x[i:i+count]))\n",
    "        i += count\n",
    "    \n",
    "    return binned_data\n",
    "\n",
    "\n",
    "def binning_xy(binned_data):\n",
    "    x = np.concatenate(([0],binned_data))\n",
    "    y = np.zeros((x.shape))\n",
    "    \n",
    "    for i in range(1,len(x)):\n",
    "        y[i] = i/len(x)\n",
    "        \n",
    "    return x,y\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc33e5",
   "metadata": {
    "id": "7bdc33e5"
   },
   "source": [
    "#### AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61579a7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "61579a7c",
    "outputId": "4c0f4c1e-b07d-4c64-c75a-0f017f485941",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(classes[:-1])):\n",
    "#     data_i = data_distance(data(df_comb,classes[:-1][i]))\n",
    "#     sigmoids_for_class(data_i, classes[:-1][i], factors[i], functions, colors,binning=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c79226",
   "metadata": {
    "id": "95c79226"
   },
   "source": [
    "#### CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a31fa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a3a31fa3",
    "outputId": "ef2da568-a999-4de9-833c-f35d1839b46b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(classes[:-1])):\n",
    "#     data_i = data_distance(data(df_CE,classes[:-1][i]))\n",
    "#     sigmoids_for_class(data_i, classes[:-1][i], factors[i], functions, colors,binning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1PvJmPU3z6R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1PvJmPU3z6R",
    "outputId": "4503e9d7-bcab-43bb-f860-e1e4bafb738b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# arctan_popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sI43T6H7307V",
   "metadata": {
    "id": "sI43T6H7307V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclid(origin, other):\n",
    "  return np.sum((origin - other) ** 2)**(1/2)\n",
    "\n",
    "def NN_distance(ref_point, data):\n",
    "  nearest_distance = 1e999\n",
    "  for point in data:\n",
    "    if euclid(ref_point, point) < nearest_distance: \n",
    "      nearest_distance = euclid(ref_point, point)\n",
    "  return nearest_distance\n",
    "\n",
    "# NN_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OrXETLFjtQX0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrXETLFjtQX0",
    "outputId": "f36829f5-89d4-40a8-aada-c4c2a7bf63b8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "original = df_comb[df_comb['class'] == 'Original']\n",
    "for target in arctan_popt:\n",
    "  nearest_distance = NN_distance(original.drop(['class'], axis = 1).to_numpy(), df_comb[df_comb['class'] == f'{target}'].drop(['class'], axis = 1).to_numpy())\n",
    "  #print(*arctan_popt[f'{target}'])\n",
    "  #print(nearest_distance)\n",
    "  # NN_dict[\"arctan_GD\"] = nearest_distance\n",
    "  #print(\"--\")\n",
    "  print(arctan_GD(nearest_distance,*arctan_popt[f'{target}']))\n",
    "  #least square fittinhg, make it as a library, can only have dataset with numbers, no images\n",
    "  #different variables, weigh in a approtate place\n",
    "  #create a library, then find a new data never see before, test it \n",
    "  #uci ml repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912184b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original = df_comb[df_comb['class'] == 'Original']\n",
    "for target in arctan_popt:\n",
    "  nearest_distance = NN_distance(original.drop(['class'], axis = 1).to_numpy(), df_comb[df_comb['class'] == f'{target}'].drop(['class'], axis = 1).to_numpy())\n",
    "  print(ERF(nearest_distance,*arctan_popt[f'{target}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b864240-2d47-4056-a119-8653d193aba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9eab7-dee6-40c3-bd8f-32bc88f56ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d445b-1952-4a54-b460-8288f734c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe8402-1e7a-41fb-9021-54937a9b0cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cdb9e-621d-42a0-a8cc-39af96977b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dfcd1-1b49-41a0-a46a-9a5e06878488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
